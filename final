#!/usr/bin/env python3
import os
import sys
import numpy as np
import rasterio
from rasterio.transform import from_bounds
from rasterio.windows import Window
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor
import torch
import torch.nn as nn
from multiprocessing import Pool, current_process, Manager
from config import *

# ---------------------------------------------------
# CONFIGURATION
# ---------------------------------------------------
OUTPUT_BASE_PATH = Path("/mnt/68_data/PROCESSED_DATA_THEMES/T6/T6S1/s2_ai_building_probability_T6S1P15")
TILE_SIZE = 1024  # Process in 1024x1024 tiles to avoid OOM
OVERLAP = 64      # Overlap between tiles to avoid edge artifacts

# Sentinel-2 bands to use (1-indexed): Blue, Green, Red, NIR, SCL
SELECTED_BANDS = [2, 3, 4, 8, 15]  # B2, B3, B4, B8, SCL

# ---------------------------------------------------
# CNN MODEL
# ---------------------------------------------------
class ImprovedCNN(nn.Module):
    def __init__(self, dropout_rate=0.3):
        super().__init__()
        self.conv1 = nn.Conv2d(4,16,3,padding='same'); self.bn1=nn.BatchNorm2d(16)
        self.conv2 = nn.Conv2d(16,32,3,padding='same'); self.bn2=nn.BatchNorm2d(32)
        self.conv3 = nn.Conv2d(32,64,3,padding='same'); self.bn3=nn.BatchNorm2d(64)
        self.conv4 = nn.Conv2d(64,64,5,padding='same'); self.bn4=nn.BatchNorm2d(64)
        self.conv5 = nn.Conv2d(64,16,1); self.bn5=nn.BatchNorm2d(16)
        self.conv6 = nn.Conv2d(16,1,1)
        self.relu = nn.ReLU(); self.dropout=nn.Dropout2d(dropout_rate); self.sigmoid=nn.Sigmoid()

    def forward(self,x):
        x = self.relu(self.bn1(self.conv1(x))); x=self.dropout(x)
        x = self.relu(self.bn2(self.conv2(x))); x=self.dropout(x)
        x = self.relu(self.bn3(self.conv3(x))); x=self.dropout(x)
        x = self.relu(self.bn4(self.conv4(x)))
        x = self.relu(self.bn5(self.conv5(x)))
        x = self.sigmoid(self.conv6(x))
        return x

# ---------------------------------------------------
# PATH TRANSFORMATION
# ---------------------------------------------------
def transform_db_path_to_actual_path(db_path):
    """Transform database path to actual file system path"""
    db_path_str = str(db_path)
    
    if '/mnt/ridam/68_data/' in db_path_str:
        actual_path = db_path_str.replace('/mnt/ridam/68_data/', '/mnt/68_data/PROCESSED_DATA_THEMES/')
        return actual_path
    elif '/mnt/ridam/115_data/' in db_path_str:
        actual_path = db_path_str.replace('/mnt/ridam/115_data/', '/home/sac/115_data/')
        return actual_path
    else:
        return db_path_str

# ---------------------------------------------------
# DATABASE FETCH
# ---------------------------------------------------
def fetch_file_records():
    """Fetch source file paths from database for T0S1P0 dataset"""
    query = """
    SELECT
        data_id,
        source_file_path,
        dataset_id,
        "timestamp"
    FROM public.published_rasters
    WHERE dataset_id = 'T0S1P0'
      AND "timestamp" >= TIMESTAMPTZ '2025-01-01 00:00:00+05:30'
      AND ST_Intersects(
            bounds,
            ST_MakeEnvelope(
                68.1, 20.1,
                74.5, 24.7,
                4326
            )
          )
    ORDER BY "timestamp"
    """
    
    try:
        conn = psycopg2.connect(
            host=DB_HOST, port=DB_PORT, dbname=DB_NAME, 
            user=DB_USER, password=DB_PASSWORD
        )
        
        records = []
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(query)
            records = cur.fetchall()
        
        conn.close()
        return records
    
    except Exception as e:
        print(f"✗ Database error: {e}")
        return []

# ---------------------------------------------------
# UTILITY FUNCTIONS
# ---------------------------------------------------
def save_raster_tif(filename, array, bbox, projection='EPSG:4326'):
    """Save numpy array as GeoTIFF with proper metadata"""
    if array.ndim == 2:
        height, width = array.shape
        array = array.reshape(1, height, width)
    else:
        _, height, width = array.shape

    transform = from_bounds(*bbox, width, height)
    
    with rasterio.open(
        filename, 'w', 
        driver='GTiff',
        height=height, 
        width=width, 
        count=array.shape[0],
        dtype=array.dtype, 
        crs=projection, 
        transform=transform,
        compress='lzw',
        tiled=True,
        blockxsize=256,
        blockysize=256
    ) as dst:
        for i in range(array.shape[0]):
            dst.write(array[i], i+1)

def is_cloudy_tile(scl_band, threshold=0.80):
    """Check if tile exceeds cloud threshold"""
    cloud_classes = {8, 9, 10, 11}
    cloud_fraction = np.isin(scl_band, list(cloud_classes)).sum() / scl_band.size
    return cloud_fraction >= threshold

# ---------------------------------------------------
# TILED PROCESSING FOR LARGE IMAGES
# ---------------------------------------------------
def process_large_image_tiled(model, src_path, device, tile_size=1024, overlap=64):
    """
    Process large image in tiles to avoid CUDA OOM
    Reads only selected bands: [2, 3, 4, 8, 15]
    Returns probability array for entire image
    """
    with rasterio.open(src_path) as src:
        full_height = src.height
        full_width = src.width
        bbox = src.bounds
        crs = src.crs
        
        # Initialize output array
        prob_output = np.zeros((full_height, full_width), dtype=np.float32)
        count_output = np.zeros((full_height, full_width), dtype=np.float32)
        
        tile_count = 0
        
        # Process each tile
        for i in range(0, full_height, tile_size - overlap):
            for j in range(0, full_width, tile_size - overlap):
                tile_count += 1
                
                # Calculate window bounds
                row_off = i
                col_off = j
                win_height = min(tile_size, full_height - i)
                win_width = min(tile_size, full_width - j)
                
                # Create window
                window = Window(col_off, row_off, win_width, win_height)
                
                # Read only selected bands [2,3,4,8,15]
                tile_data = src.read(SELECTED_BANDS, window=window)
                
                # Check if tile is empty
                if not np.any(tile_data != 0):
                    continue
                
                # Extract first 4 bands for model and SCL band
                msi_bands = tile_data[:4]
                scl_band = tile_data[4]
                
                # Skip heavily clouded tiles
                if is_cloudy_tile(scl_band, 0.8):
                    continue
                
                # Normalize to [0, 1] range
                tile_normalized = msi_bands.astype(np.float32) / 10000.0
                
                # Run inference
                model.eval()
                with torch.no_grad():
                    tensor = torch.from_numpy(tile_normalized).unsqueeze(0).to(device)
                    prob_tile = model(tensor).cpu().numpy()[0, 0]
                    
                    # Free GPU memory
                    del tensor
                    torch.cuda.empty_cache()
                
                # Add to output
                prob_output[row_off:row_off+win_height, col_off:col_off+win_width] += prob_tile
                count_output[row_off:row_off+win_height, col_off:col_off+win_width] += 1
        
        # Average overlapping regions
        count_output[count_output == 0] = 1
        prob_output = prob_output / count_output
        
        return prob_output, bbox, crs

# ---------------------------------------------------
# WORKER FUNCTION FOR MULTIPROCESSING
# ---------------------------------------------------
def process_file_worker(args):
    """
    Worker function that processes a single file on assigned GPU
    Each worker gets a GPU assigned based on worker ID
    """
    record, processed_set, num_gpus = args
    
    # Get GPU ID for this worker (round-robin assignment)
    worker_id = int(current_process().name.split('-')[-1]) - 1
    gpu_id = worker_id % num_gpus
    device = torch.device(f'cuda:{gpu_id}')
    
    db_path = record['source_file_path']
    timestamp = record['timestamp']
    data_id = record['data_id']
    
    # Transform database path to actual file system path
    actual_path = transform_db_path_to_actual_path(db_path)
    
    proc_name = current_process().name
    print(f"[{proc_name}] GPU {gpu_id}: Processing {data_id}")
    
    # Check if source file exists
    if not os.path.exists(actual_path):
        print(f"[{proc_name}] ✗ Source file not found: {actual_path}")
        return {'status': 'error', 'gpu': gpu_id}
    
    # Extract date components
    year = timestamp.strftime("%Y")
    month = timestamp.strftime("%m")
    day = timestamp.strftime("%d")
    date_str = f"{year}{month}{day}"
    
    # Create output directory
    target_dir = OUTPUT_BASE_PATH / year / month / day
    target_dir.mkdir(parents=True, exist_ok=True)
    
    # Output filename
    dst_file = target_dir / f"MSI_probability_{date_str}_{data_id}.tif"
    
    # Skip if already processed
    if str(dst_file) in processed_set or dst_file.exists():
        print(f"[{proc_name}] ⊘ Already processed: {dst_file.name}")
        return {'status': 'skipped', 'gpu': gpu_id}
    
    try:
        # Load model on this GPU
        model = ImprovedCNN()
        model.load_state_dict(
            torch.load('best_model_seasonal.pth', map_location='cpu', weights_only=True)
        )
        model.to(device)
        model.eval()
        
        # Check cloud coverage
        with rasterio.open(actual_path) as src:
            scl_band = src.read(15)
        
        if is_cloudy_tile(scl_band, 0.8):
            cloud_pct = (np.isin(scl_band, [8,9,10,11]).sum() / scl_band.size) * 100
            print(f"[{proc_name}] ✗ Cloudy tile ({cloud_pct:.1f}% clouds)")
            return {'status': 'cloudy', 'gpu': gpu_id}
        
        # Process image in tiles
        prob_output, bbox, crs = process_large_image_tiled(
            model, actual_path, device=device,
            tile_size=TILE_SIZE, overlap=OVERLAP
        )
        
        # Scale probability to 0-100
        prob_scaled = (prob_output * 100).astype(np.uint16)
        
        # Save probability raster
        save_raster_tif(dst_file, prob_scaled, bbox, crs)
        
        # Log processed file
        with open('processed.log', 'a') as f:
            f.write(f"{dst_file}\n")
        
        print(f"[{proc_name}] ✓ Saved: {dst_file.name}")
        
        # Clean up
        del model
        torch.cuda.empty_cache()
        
        return {'status': 'success', 'gpu': gpu_id, 'file': str(dst_file)}
        
    except Exception as e:
        print(f"[{proc_name}] ✗ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return {'status': 'error', 'gpu': gpu_id, 'error': str(e)}

# ---------------------------------------------------
# MAIN PIPELINE
# ---------------------------------------------------
def run_pipeline():
    """Main processing pipeline with multi-GPU parallel processing"""
    
    print("="*70)
    print("SENTINEL-2 BUILDING PROBABILITY PREDICTION PIPELINE")
    print("="*70)
    print(f"\nBand Selection: {SELECTED_BANDS}")
    print(f"  B2 (Blue), B3 (Green), B4 (Red), B8 (NIR), B15 (SCL)")
    print(f"\nTiled Processing: {TILE_SIZE}x{TILE_SIZE} pixels with {OVERLAP}px overlap")
    print("\nPath Mapping:")
    print("  /mnt/ridam/68_data/  → /mnt/68_data/PROCESSED_DATA_THEMES/")
    print("  /mnt/ridam/115_data/ → /home/sac/115_data/")
    print()
    
    # Load processed files log
    processed_set = set()
    if os.path.exists('processed.log'):
        with open('processed.log', 'r') as f:
            processed_set = set(line.strip() for line in f.readlines())
        print(f"Found {len(processed_set)} already processed files\n")
    
    # Check GPU availability
    if not torch.cuda.is_available():
        print("✗ CUDA not available!")
        return
    
    num_gpus = torch.cuda.device_count()
    print(f"Detected {num_gpus} GPUs:")
    for i in range(num_gpus):
        print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
        print(f"          Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB")
    
    # Calculate number of parallel workers (1 per GPU)
    num_workers = num_gpus
    print(f"\nUsing {num_workers} parallel workers (1 per GPU)")
    print(f"Output directory: {OUTPUT_BASE_PATH}")
    print()
    
    # Fetch file records
    print("Fetching file records from database...")
    records = fetch_file_records()
    
    if not records:
        print("✗ No records found or database error")
        return
    
    print(f"✓ Found {len(records)} files to process\n")
    print("="*70)
    print("Starting parallel processing...\n")
    
    # Prepare arguments for workers
    worker_args = [(record, processed_set, num_gpus) for record in records]
    
    # Process files in parallel using multiprocessing
    success_count = 0
    skip_count = 0
    error_count = 0
    cloudy_count = 0
    
    with Pool(processes=num_workers) as pool:
        for result in pool.imap_unordered(process_file_worker, worker_args):
            if result['status'] == 'success':
                success_count += 1
            elif result['status'] == 'skipped':
                skip_count += 1
            elif result['status'] == 'cloudy':
                cloudy_count += 1
            else:
                error_count += 1
            
            # Progress update every 10 files
            total_processed = success_count + skip_count + error_count + cloudy_count
            if total_processed % 10 == 0:
                print(f"\n--- Progress: {total_processed}/{len(records)} files ---")
                print(f"    ✓ Success: {success_count} | ⊘ Skipped: {skip_count}")
                print(f"    ☁ Cloudy: {cloudy_count} | ✗ Error: {error_count}\n")
    
    # Summary
    print("\n" + "="*70)
    print("PROCESSING COMPLETE")
    print("="*70)
    print(f"Total files:      {len(records)}")
    print(f"✓ Processed:      {success_count}")
    print(f"⊘ Skipped:        {skip_count}")
    print(f"☁ Cloudy:         {cloudy_count}")
    print(f"✗ Failed/Error:   {error_count}")
    print("="*70)

# ---------------------------------------------------
# ENTRY POINT
# ---------------------------------------------------
if __name__ == '__main__':
    # Required for CUDA multiprocessing
    torch.multiprocessing.set_start_method('spawn', force=True)
    
    try:
        run_pipeline()
    except KeyboardInterrupt:
        print("\n\n✗ Pipeline interrupted by user")
    except Exception as e:
        print(f"\n✗ Pipeline failed with error: {e}")
        import traceback
        traceback.print_exc()
