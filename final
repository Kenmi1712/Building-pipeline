#!/usr/bin/env python3
import os
import sys
import numpy as np
import rasterio
from rasterio.transform import from_bounds
from rasterio.windows import Window
from pathlib import Path
import psycopg2
from psycopg2.extras import RealDictCursor
import torch
import torch.nn as nn
from config import *

# ---------------------------------------------------
# CONFIGURATION
# ---------------------------------------------------
OUTPUT_BASE_PATH = Path("/mnt/68_data/PROCESSED_DATA_THEMES/T6/T6S1/s2_ai_building_probability_T6S1P15")
TILE_SIZE = 1024  # Process in 1024x1024 tiles to avoid OOM
OVERLAP = 64      # Overlap between tiles to avoid edge artifacts

# ---------------------------------------------------
# CNN MODEL
# ---------------------------------------------------
class ImprovedCNN(nn.Module):
    def __init__(self, dropout_rate=0.3):
        super().__init__()
        self.conv1 = nn.Conv2d(4,16,3,padding='same'); self.bn1=nn.BatchNorm2d(16)
        self.conv2 = nn.Conv2d(16,32,3,padding='same'); self.bn2=nn.BatchNorm2d(32)
        self.conv3 = nn.Conv2d(32,64,3,padding='same'); self.bn3=nn.BatchNorm2d(64)
        self.conv4 = nn.Conv2d(64,64,5,padding='same'); self.bn4=nn.BatchNorm2d(64)
        self.conv5 = nn.Conv2d(64,16,1); self.bn5=nn.BatchNorm2d(16)
        self.conv6 = nn.Conv2d(16,1,1)
        self.relu = nn.ReLU(); self.dropout=nn.Dropout2d(dropout_rate); self.sigmoid=nn.Sigmoid()

    def forward(self,x):
        x = self.relu(self.bn1(self.conv1(x))); x=self.dropout(x)
        x = self.relu(self.bn2(self.conv2(x))); x=self.dropout(x)
        x = self.relu(self.bn3(self.conv3(x))); x=self.dropout(x)
        x = self.relu(self.bn4(self.conv4(x)))
        x = self.relu(self.bn5(self.conv5(x)))
        x = self.sigmoid(self.conv6(x))
        return x

# ---------------------------------------------------
# PATH TRANSFORMATION
# ---------------------------------------------------
def transform_db_path_to_actual_path(db_path):
    """
    Transform database path to actual file system path
    
    /mnt/ridam/68_data/T0/T0S1/... → /mnt/68_data/PROCESSED_DATA_THEMES/T0/T0S1/...
    /mnt/ridam/115_data/T0/T0S1/... → /home/sac/115_data/T0/T0S1/...
    """
    db_path_str = str(db_path)
    
    if '/mnt/ridam/68_data/' in db_path_str:
        actual_path = db_path_str.replace('/mnt/ridam/68_data/', '/mnt/68_data/PROCESSED_DATA_THEMES/')
        return actual_path
    elif '/mnt/ridam/115_data/' in db_path_str:
        actual_path = db_path_str.replace('/mnt/ridam/115_data/', '/home/sac/115_data/')
        return actual_path
    else:
        return db_path_str

# ---------------------------------------------------
# DATABASE FETCH
# ---------------------------------------------------
def fetch_file_records():
    """Fetch source file paths from database for T0S1P0 dataset"""
    query = """
    SELECT
        data_id,
        source_file_path,
        dataset_id,
        "timestamp"
    FROM public.published_rasters
    WHERE dataset_id = 'T0S1P0'
      AND "timestamp" >= TIMESTAMPTZ '2025-01-01 00:00:00+05:30'
      AND ST_Intersects(
            bounds,
            ST_MakeEnvelope(
                68.1, 20.1,
                74.5, 24.7,
                4326
            )
          )
    ORDER BY "timestamp"
    """
    
    try:
        conn = psycopg2.connect(
            host=DB_HOST, port=DB_PORT, dbname=DB_NAME, 
            user=DB_USER, password=DB_PASSWORD
        )
        
        records = []
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(query)
            records = cur.fetchall()
        
        conn.close()
        return records
    
    except Exception as e:
        print(f"✗ Database error: {e}")
        return []

# ---------------------------------------------------
# UTILITY FUNCTIONS
# ---------------------------------------------------
def save_raster_tif(filename, array, bbox, projection='EPSG:4326'):
    """Save numpy array as GeoTIFF with proper metadata"""
    if array.ndim == 2:
        height, width = array.shape
        array = array.reshape(1, height, width)
    else:
        _, height, width = array.shape

    transform = from_bounds(*bbox, width, height)
    
    with rasterio.open(
        filename, 'w', 
        driver='GTiff',
        height=height, 
        width=width, 
        count=array.shape[0],
        dtype=array.dtype, 
        crs=projection, 
        transform=transform,
        compress='lzw',
        tiled=True,
        blockxsize=256,
        blockysize=256
    ) as dst:
        for i in range(array.shape[0]):
            dst.write(array[i], i+1)

def standardize_channels(msi_array, target_channels=4):
    """Standardize MSI array to target number of channels"""
    c, h, w = msi_array.shape
    if c == target_channels:
        return msi_array
    elif c > target_channels:
        return msi_array[:target_channels]
    else:
        padded = np.zeros((target_channels, h, w), dtype=msi_array.dtype)
        padded[:c] = msi_array
        return padded

def apply_cloud_mask(msi_array, cloud_band_values=[4,5,7], fill_value=-1):
    """Apply cloud masking based on SCL band values"""
    last_band = msi_array[-1]
    mask = np.isin(last_band, cloud_band_values)
    msi_masked = msi_array.copy()
    for i in range(msi_array.shape[0]):
        msi_masked[i, ~mask] = fill_value
    return msi_masked, mask

def is_cloudy_tile(scl_band, threshold=0.80):
    """Check if tile exceeds cloud threshold"""
    cloud_classes = {8, 9, 10, 11}
    cloud_fraction = np.isin(scl_band, list(cloud_classes)).sum() / scl_band.size
    return cloud_fraction >= threshold

# ---------------------------------------------------
# TILED PROCESSING FOR LARGE IMAGES
# ---------------------------------------------------
def process_large_image_tiled(model, src_path, device='cuda', tile_size=1024, overlap=64):
    """
    Process large image in tiles to avoid CUDA OOM
    Returns probability array for entire image
    """
    with rasterio.open(src_path) as src:
        full_height = src.height
        full_width = src.width
        bbox = src.bounds
        crs = src.crs
        
        # Initialize output array
        prob_output = np.zeros((full_height, full_width), dtype=np.float32)
        count_output = np.zeros((full_height, full_width), dtype=np.float32)
        
        # Calculate number of tiles
        n_tiles_y = (full_height + tile_size - 1) // tile_size
        n_tiles_x = (full_width + tile_size - 1) // tile_size
        total_tiles = n_tiles_y * n_tiles_x
        
        print(f"  └─ Processing {n_tiles_y}x{n_tiles_x} = {total_tiles} tiles")
        
        tile_count = 0
        
        # Process each tile
        for i in range(0, full_height, tile_size - overlap):
            for j in range(0, full_width, tile_size - overlap):
                tile_count += 1
                
                # Calculate window bounds
                row_off = i
                col_off = j
                win_height = min(tile_size, full_height - i)
                win_width = min(tile_size, full_width - j)
                
                # Create window
                window = Window(col_off, row_off, win_width, win_height)
                
                # Read tile data
                tile_data = src.read(window=window)
                
                # Check if tile is empty
                if not np.any(tile_data != 0):
                    continue
                
                # Standardize channels
                tile_data = standardize_channels(tile_data, 4)
                
                # Normalize
                tile_normalized = tile_data.astype(np.float32) / 10000.0
                
                # Run inference
                model.eval()
                with torch.no_grad():
                    tensor = torch.from_numpy(tile_normalized).unsqueeze(0).to(device)
                    prob_tile = model(tensor).cpu().numpy()[0, 0]
                    
                    # Free GPU memory
                    del tensor
                    torch.cuda.empty_cache()
                
                # Add to output (weighted averaging for overlapping regions)
                prob_output[row_off:row_off+win_height, col_off:col_off+win_width] += prob_tile
                count_output[row_off:row_off+win_height, col_off:col_off+win_width] += 1
                
                if tile_count % 10 == 0:
                    print(f"      Tile {tile_count}/{total_tiles} processed")
        
        # Average overlapping regions
        count_output[count_output == 0] = 1  # Avoid division by zero
        prob_output = prob_output / count_output
        
        return prob_output, bbox, crs

# ---------------------------------------------------
# PROCESS SINGLE FILE
# ---------------------------------------------------
def process_file_record(model, record, processed_set, device='cuda', threshold=0.4):
    """Process a single Sentinel-2 file from database record"""
    db_path = record['source_file_path']
    timestamp = record['timestamp']
    data_id = record['data_id']
    
    # Transform database path to actual file system path
    actual_path = transform_db_path_to_actual_path(db_path)
    
    print(f"  DB Path:     {db_path}")
    print(f"  Actual Path: {actual_path}")
    
    # Check if source file exists
    if not os.path.exists(actual_path):
        print(f"  ✗ Source file not found at actual path")
        return False
    
    # Extract date components
    year = timestamp.strftime("%Y")
    month = timestamp.strftime("%m")
    day = timestamp.strftime("%d")
    date_str = f"{year}{month}{day}"
    
    # Create output directory
    target_dir = OUTPUT_BASE_PATH / year / month / day
    target_dir.mkdir(parents=True, exist_ok=True)
    
    # Output filename
    dst_file = target_dir / f"MSI_probability_{date_str}_{data_id}.tif"
    
    # Skip if already processed
    if str(dst_file) in processed_set or dst_file.exists():
        print(f"  ⊘ Already processed: {dst_file.name}")
        return False
    
    try:
        # Read metadata first
        with rasterio.open(actual_path) as src:
            img_shape = (src.count, src.height, src.width)
            print(f"  └─ Bands: {img_shape[0]}, Size: {img_shape[1]}x{img_shape[2]}")
            
            # Check cloud coverage using SCL band
            scl_band = src.read(5) if src.count > 4 else src.read(src.count)
        
        if is_cloudy_tile(scl_band, 0.8):
            cloud_pct = (np.isin(scl_band, [8,9,10,11]).sum() / scl_band.size) * 100
            print(f"  ✗ Cloudy tile ({cloud_pct:.1f}% clouds), skipping")
            return False
        
        # Process image in tiles
        prob_output, bbox, crs = process_large_image_tiled(
            model, actual_path, device=device, 
            tile_size=TILE_SIZE, overlap=OVERLAP
        )
        
        # Scale probability to 0-100
        prob_scaled = (prob_output * 100).astype(np.uint16)
        
        # Save probability raster
        save_raster_tif(dst_file, prob_scaled, bbox, crs)
        
        # Add to processed set
        processed_set.add(str(dst_file))
        
        # Log processed file
        with open('processed.log', 'a') as f:
            f.write(f"{dst_file}\n")
        
        print(f"  ✓ Saved: {dst_file.name}")
        return True
        
    except Exception as e:
        print(f"  ✗ ERROR: {e}")
        import traceback
        traceback.print_exc()
        return False

# ---------------------------------------------------
# MAIN PIPELINE
# ---------------------------------------------------
def run_pipeline():
    """Main processing pipeline"""
    
    print("="*70)
    print("SENTINEL-2 BUILDING PROBABILITY PREDICTION PIPELINE")
    print("="*70)
    print(f"\nTiled Processing: {TILE_SIZE}x{TILE_SIZE} pixels with {OVERLAP}px overlap")
    print("\nPath Mapping:")
    print("  /mnt/ridam/68_data/  → /mnt/68_data/PROCESSED_DATA_THEMES/")
    print("  /mnt/ridam/115_data/ → /home/sac/115_data/")
    print()
    
    # Load processed files log
    processed_set = set()
    if os.path.exists('processed.log'):
        with open('processed.log', 'r') as f:
            processed_set = set(line.strip() for line in f.readlines())
        print(f"Found {len(processed_set)} already processed files\n")
    
    # Load CNN model
    print("Loading CNN model...")
    model = ImprovedCNN()
    
    if not os.path.exists('best_model_seasonal.pth'):
        print("✗ Model file 'best_model_seasonal.pth' not found!")
        return
    
    model.load_state_dict(
        torch.load('best_model_seasonal.pth', map_location='cpu', weights_only=True)
    )
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model.to(device)
    
    print(f"✓ Model loaded successfully")
    print(f"  Device: {device}")
    
    if device == 'cuda':
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
        print(f"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    
    print(f"\nOutput directory: {OUTPUT_BASE_PATH}")
    print()
    
    # Fetch file records
    print("Fetching file records from database...")
    records = fetch_file_records()
    
    if not records:
        print("✗ No records found or database error")
        return
    
    print(f"✓ Found {len(records)} files to process\n")
    print("="*70)
    
    # Process each file
    success_count = 0
    skip_count = 0
    error_count = 0
    
    for i, record in enumerate(records, 1):
        print(f"\n[{i}/{len(records)}] {record['data_id']}")
        print(f"  Date: {record['timestamp'].strftime('%Y-%m-%d')}")
        
        result = process_file_record(
            model=model,
            record=record,
            processed_set=processed_set,
            device=device,
            threshold=0.4
        )
        
        if result:
            success_count += 1
        elif str(Path(OUTPUT_BASE_PATH) / record['timestamp'].strftime('%Y/%m/%d') / 
                 f"MSI_probability_{record['timestamp'].strftime('%Y%m%d')}_{record['data_id']}.tif") in processed_set:
            skip_count += 1
        else:
            error_count += 1
        
        # Clear GPU cache periodically
        if device == 'cuda' and i % 10 == 0:
            torch.cuda.empty_cache()
    
    # Summary
    print("\n" + "="*70)
    print("PROCESSING COMPLETE")
    print("="*70)
    print(f"Total files:      {len(records)}")
    print(f"✓ Processed:      {success_count}")
    print(f"⊘ Skipped:        {skip_count}")
    print(f"✗ Failed/Empty:   {error_count}")
    print("="*70)

# ---------------------------------------------------
# ENTRY POINT
# ---------------------------------------------------
if __name__ == '__main__':
    try:
        run_pipeline()
    except KeyboardInterrupt:
        print("\n\n✗ Pipeline interrupted by user")
    except Exception as e:
        print(f"\n✗ Pipeline failed with error: {e}")
        import traceback
        traceback.print_exc()
