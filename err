✔ ~/Documents/urban_model/Full_guj $python combine.py 
======================================================================
SENTINEL-2 BUILDING PROBABILITY PREDICTION PIPELINE
======================================================================

Path Mapping:
  /mnt/ridam/68_data/  → /mnt/68_data/PROCESSED_DATA_THEMES/
  /mnt/ridam/115_data/ → /home/sac/115_data/

Loading CNN model...
✓ Model loaded successfully
  Device: cuda
  GPU: Tesla V100-SXM2-32GB
  Memory: 34.1 GB

Output directory: /mnt/68_data/PROCESSED_DATA_THEMES/T6/T6S1/s2_ai_building_probability_T6S1P15

Fetching file records from database...
✓ Found 6241 files to process

======================================================================

[1/6241] SEN2A_MSI_zzz_01JAN2025_005_T42QZM_ESA_STUBBAOJD_20250101T085751_20250101P0000
  Date: 2025-01-01
  DB Path:     /mnt/ridam/68_data/T0/T0S1/T0S1P0/2025/01/01/SEN2A_MSI_zzz_01JAN2025_005_T42QZM_ESA_STUBBAOJD_20250101T085751_20250101P0000.tif
  Actual Path: /mnt/68_data/PROCESSED_DATA_THEMES/T0/T0S1/T0S1P0/2025/01/01/SEN2A_MSI_zzz_01JAN2025_005_T42QZM_ESA_STUBBAOJD_20250101T085751_20250101P0000.tif
  └─ Bands: 15, Size: 10980x10980
  ✗ ERROR: CUDA out of memory. Tried to allocate 14.37 GiB. GPU 0 has a total capacity of 31.74 GiB of which 8.01 GiB is free. Including non-PyTorch memory, this process has 23.72 GiB memory in use. Of the allocated memory 23.36 GiB is allocated by PyTorch, and 4.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home/sac/Documents/urban_model/Full_guj/combine.py", line 557, in process_file_record
    prob = model(tensor).cpu().numpy()[0, 0]
  File "/home/sac/miniconda3/envs/geo_torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/sac/miniconda3/envs/geo_torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sac/Documents/urban_model/Full_guj/combine.py", line 341, in forward
    x = self.relu(self.bn2(self.conv2(x))); x=self.dropout(x)
  File "/home/sac/miniconda3/envs/geo_torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/sac/miniconda3/envs/geo_torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/sac/miniconda3/envs/geo_torch_env/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py", line 193, in forward
    return F.batch_norm(
  File "/home/sac/miniconda3/envs/geo_torch_env/lib/python3.10/site-packages/torch/nn/functional.py", line 2813, in batch_norm
    return torch.batch_norm(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.37 GiB. GPU 0 has a total capacity of 31.74 GiB of which 8.01 GiB is free. Including non-PyTorch memory, this process has 23.72 GiB memory in use. Of the allocated memory 23.36 GiB is allocated by PyTorch, and 4.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

[2/6241] SEN2A_MSI_zzz_01JAN2025_005_T43QCF_ESA_STUBBAOJD_20250101T085751_20250101P0000
  Date: 2025-01-01
  DB Path:     /mnt/ridam/68_data/T0/T0S1/T0S1P0/2025/01/01/SEN2A_MSI_zzz_01JAN2025_005_T43QCF_ESA_STUBBAOJD_20250101T085751_20250101P0000.tif
  Actual Path: /mnt/68_data/PROCESSED_DATA_THEMES/T0/T0S1/T0S1P0/2025/01/01/SEN2A_MSI_zzz_01JAN2025_005_T43QCF_ESA_STUBBAOJD_20250101T085751_20250101P0000.tif
^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C^C

✗ Pipeline interrupted by user
^C^C
